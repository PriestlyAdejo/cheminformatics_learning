import os
import subprocess
from tqdm import tqdm
import torch

def prepare_ligands(smiles, num_devices):
    """
    Converts SMILES strings to .pdbqt files using Open Babel in parallel across multiple devices.
    """
    for device in range(num_devices):
        os.makedirs(f'ligands/{device}', exist_ok=True)
    
    processes = []
    for i, smi in enumerate(smiles):
        device = i % num_devices
        cmd = f'obabel -:"{smi}" -O ligands/{device}/ligand{i}.pdbqt -p 7.4 --partialcharge gasteiger --gen3d'
        process = subprocess.Popen(cmd, shell=True, stderr=subprocess.DEVNULL)
        processes.append(process)
    
    # Wait for all processes to complete
    for p in processes:
        p.wait()

def run_autodock_gpu(ligand_paths, protein_path, grid_file, output_dir, num_devices, 
                     num_runs=20, exhaustiveness=8, seed=None):
    """
    Performs docking using AutoDock-GPU on multiple ligands against a single protein target,
    distributing the workload across multiple GPU devices.

    Parameters:
    - ligand_paths: List[str], paths to ligand PDBQT files.
    - protein_path: str, path to the protein PDBQT file.
    - grid_file: str, path to the grid map files descriptor (.fld).
    - output_dir: str, directory to save output files.
    - num_devices: int, number of GPU devices to use.
    - num_runs: int, number of LGA runs to perform (default 20).
    - exhaustiveness: int, exhaustiveness of the search (similar concept, not directly AutoDock-GPU parameter).
    - seed: int or None, random seed for reproducibility.

    Returns:
    - List of paths to the output files generated by the docking.
    """

    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Generate commands for each ligand
    commands = []
    for device_id, ligand_path in enumerate(ligand_paths):
        output_file_name = f"{os.path.splitext(os.path.basename(ligand_path))[0]}_output.txt"
        output_file_path = os.path.join(output_dir, output_file_name)

        command = [
            "autodock_gpu_64wi", 
            "--ffile", grid_file, 
            "--lfile", ligand_path, 
            "--nrun", str(num_runs), 
            "--devnum", str(device_id % num_devices + 1),  # Devices are 1-indexed
            "--xmloutput", "0",  # Disable XML output for simplicity
            "--resnam", os.path.splitext(output_file_name)[0]
        ]

        if seed is not None:
            command += ["--seed", str(seed)]

        # Redirect output to a file
        command_str = " ".join(command) + f" > {output_file_path}"
        commands.append(command_str)

    # Execute commands in parallel, respecting the number of devices
    processes = []
    for cmd in commands:
        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        processes.append(p)
        if len(processes) >= num_devices:
            # Wait for processes to complete before starting more
            [p.wait() for p in processes]
            processes.clear()

    # Final cleanup: Wait for any remaining processes to complete
    [p.wait() for p in processes]

    # Return paths to output files
    output_files = [os.path.join(output_dir, f"{os.path.splitext(os.path.basename(ligand))[0]}_output.txt") for ligand in ligand_paths]
    
    # Read outputs from the files
    docking_outputs = []
    for output_file in tqdm(output_files, desc="Gathering outputs"):
        with open(output_file, 'r') as file:
            output_text = file.read()
            docking_outputs.append(output_text)
            
    return docking_outputs
    

def dock(
    ligand_path,
    protein_path,
    output_path,
    num_poses=10,
    random_seed=None,
    log=True,
    num_devices=torch.cuda.device_count(),
    autodock="autodock_gpu_64wi"
):
    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Generate commands for each ligand
    commands = []
    for device_id, ligand_path in enumerate(ligand_paths):
        output_file_name = f"{os.path.splitext(os.path.basename(ligand_path))[0]}_output.txt"
        output_file_path = os.path.join(output_dir, output_file_name)

        command = [
            autodock, 
            "--ffile", grid_file, 
            "--lfile", ligand_path, 
            "--nrun", str(num_runs), 
            "--devnum", str(device_id % num_devices + 1),  # Devices are 1-indexed
            "--xmloutput", "0",  # Disable XML output for simplicity
            "--resnam", os.path.splitext(output_file_name)[0]
        ]

        if seed is not None:
            command += ["--seed", str(seed)]

        # Redirect output to a file
        command_str = " ".join(command) + f" > {output_file_path}"
        commands.append(command_str)

    # Execute commands in parallel, respecting the number of devices
    processes = []
    for cmd in commands:
        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        processes.append(p)
        if len(processes) >= num_devices:
            # Wait for processes to complete before starting more
            [p.wait() for p in processes]
            processes.clear()

    # Final cleanup: Wait for any remaining processes to complete
    [p.wait() for p in processes]

    # Return paths to output files
    output_files = [os.path.join(output_dir, f"{os.path.splitext(os.path.basename(ligand))[0]}_output.txt") for ligand in ligand_paths]
    
    # Read outputs from the files
    docking_outputs = []
    for output_file in tqdm(output_files, desc="Gathering outputs"):
        with open(output_file, 'r') as file:
            output_text = file.read()
            docking_outputs.append(output_text)
            
    return docking_outputs
    

def convert_log_to_dataframe(raw_log):
    """
    Convert docking's raw output log into a pandas.DataFrame.

    Parameters
    ----------
    raw_log : str
        Raw output log generated after docking.

    Returns
    -------
    pandas.DataFrame
        DataFrame containing columns 'mode', 'affinity[kcal/mol]',
        'dist from best mode_rmsd_l.b', and 'dist from best mode_rmsd_u.b'
        for each generated docking pose.
    """

    # Remove the unnecessary parts and extract the results table as list of lines
    # The table starts after the line containing: -----+------------+----------+----------
    # and ends before the word "Refine"
    log = (
        raw_log.split("-----+------------+----------+----------")[1]
        .split("Refine")[0]
        .strip()
        .split("\n")
    )

    # parse each line and remove everything except the numbers
    for index in range(len(log)):
        # turn each line into a list
        log[index] = log[index].strip().split(" ")
        # First element is the mode, which is an int.
        # The rest of the elements are either empty strings, or floats
        # Elements that are not empty strings should be extracted
        # (first element as int and the rest as floats)
        log[index] = [int(log[index][0])] + [
            float(value) for value in log[index][1:] if value != ""
        ]

    df = pd.DataFrame(
        log,
        columns=[
            "mode",
            "affinity[kcal/mol]",
            "dist from best mode_rmsd_l.b",
            "dist from best mode_rmsd_u.b",
        ],
    )
    df.index = df["mode"]
    df.drop("mode", axis=1, inplace=True)
    return df
